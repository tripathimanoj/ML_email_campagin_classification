{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modulel 6 : Capstone Project #\n",
        "## Project Title : Email Campaign Effectiveness Prediction ##\n",
        "\n",
        "#### Click the image for GitHub Repository ####\n",
        "<a href=\"https://github.com/tripathimanoj/ML_email_campagin_classification\" target=\"_parent\"><img src=\"git_logo.png\" alt=\"GitHub repository\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI9MU5bGAK9o"
      },
      "source": [
        "## **Project Title : Email Campaign Effectiveness Prediction**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7gflv1ABF5k"
      },
      "source": [
        "## **Problem Description**\n",
        "\n",
        "Most of the small to medium business owners are making effective use of Gmail-based\n",
        "Email marketing Strategies for offline targeting of converting their prospective customers into\n",
        "leads so that they stay with them in business.\n",
        "The main objective is to create a machine learning model to characterize the mail and track\n",
        "the mail that is ignored; read; acknowledged by the reader.\n",
        "Data columns are self-explanatory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E-Lakt9wQHp"
      },
      "source": [
        "### **Introduction:**\n",
        "Email Marketing can be defined as a marketing technique in which businesses stay connected with their customers through emails, making them aware about their new products, updates, important notices related to the products they are using.\n",
        "\n",
        "Most importantly, email marketing allows businesses to build relationships with leads, new customers and past customers. It's a way to communicate directly to the customers in their inbox, at a time that is convenient for them. With the right messaging tone and strategies, emails are one of the most important marketing channels.\n",
        "\n",
        "We all subscribe to many different kinds of businesses through emails because it's required to do so, sometimes to get digital receipts of the things we bought or to get digital information about the business to stay updated. But many of times we do not tend to read an email due to a number of reasons - to name a few would be- no proper structure, too many images, too many links inside the mail, complex vocabulary used or simply too long emails.\n",
        "\n",
        "In this problem statement, we will be trying to create machine learning models that characterize and predict whether the mail is ignored, read or acknowledged by the reader. In addition to this, we will be trying to analyze and find all the features that are important for an email to not get ignored.\n",
        "\n",
        "So let's begin!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qvbSdTsBAJ5L"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#for data visualization\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "#Importing important libraries and modules\n",
        "#for data reading and manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#for data visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "plt.rcParams.update({'figure.figsize':(8,5),'figure.dpi':100})\n",
        "\n",
        "#VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "#Modelling\n",
        "#Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Grid Search for Hyperparameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, roc_auc_score, f1_score, recall_score,roc_curve, classification_report\n",
        "\n",
        "#to ignore warnings\n",
        "import warnings    \n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pfua0nkq5UKk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File found at: .\\data_email_campaign.csv\n",
            "Data loaded successfully from local path.\n"
          ]
        }
      ],
      "source": [
        "#reading the csv dataset either from the local path or from the github repository...\n",
        "# Data Loading...\n",
        "import os\n",
        "def find_file(file_name, folder=\".\"):\n",
        "    for root, dirs, files in os.walk(folder):\n",
        "        if file_name in files:\n",
        "            return os.path.join(root, file_name)\n",
        "    return None\n",
        "\n",
        "file_path = find_file(\"data_email_campaign.csv\")\n",
        "if file_path:\n",
        "    print(f\"File found at: {file_path}\")\n",
        "    df_orig = pd.read_csv(file_path)\n",
        "    print(\"Data loaded successfully from local path.\")\n",
        "else:\n",
        "    print(\"File not found in the current folder. Reading data from GITHUB repo ==> \")\n",
        "    df_orig = pd.read_csv(\"https://raw.githubusercontent.com/tripathimanoj/ML_email_campagin_classification/main/data_email_campaign.csv\")\n",
        "    print(\"Data loaded successfully from GITHUB repo.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "FN4CFAXq5tco",
        "outputId": "179445bb-e533-4e12-d400-2c089d4a8a6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email_ID</th>\n",
              "      <th>Email_Type</th>\n",
              "      <th>Subject_Hotness_Score</th>\n",
              "      <th>Email_Source_Type</th>\n",
              "      <th>Customer_Location</th>\n",
              "      <th>Email_Campaign_Type</th>\n",
              "      <th>Total_Past_Communications</th>\n",
              "      <th>Time_Email_sent_Category</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Total_Links</th>\n",
              "      <th>Total_Images</th>\n",
              "      <th>Email_Status</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EMA00081000034500</td>\n",
              "      <td>1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "      <td>E</td>\n",
              "      <td>2</td>\n",
              "      <td>33.0</td>\n",
              "      <td>1</td>\n",
              "      <td>440</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EMA00081000045360</td>\n",
              "      <td>2</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>15.0</td>\n",
              "      <td>2</td>\n",
              "      <td>504</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EMA00081000066290</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>3</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2</td>\n",
              "      <td>962</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EMA00081000076560</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "      <td>E</td>\n",
              "      <td>2</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2</td>\n",
              "      <td>610</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EMA00081000109720</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>C</td>\n",
              "      <td>3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2</td>\n",
              "      <td>947</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Email_ID  Email_Type  Subject_Hotness_Score  Email_Source_Type  \\\n",
              "0  EMA00081000034500           1                    2.2                  2   \n",
              "1  EMA00081000045360           2                    2.1                  1   \n",
              "2  EMA00081000066290           2                    0.1                  1   \n",
              "3  EMA00081000076560           1                    3.0                  2   \n",
              "4  EMA00081000109720           1                    0.0                  2   \n",
              "\n",
              "  Customer_Location  Email_Campaign_Type  Total_Past_Communications  \\\n",
              "0                 E                    2                       33.0   \n",
              "1               NaN                    2                       15.0   \n",
              "2                 B                    3                       36.0   \n",
              "3                 E                    2                       25.0   \n",
              "4                 C                    3                       18.0   \n",
              "\n",
              "   Time_Email_sent_Category  Word_Count  Total_Links  Total_Images  \\\n",
              "0                         1         440          8.0           0.0   \n",
              "1                         2         504          5.0           0.0   \n",
              "2                         2         962          5.0           0.0   \n",
              "3                         2         610         16.0           0.0   \n",
              "4                         2         947          4.0           0.0   \n",
              "\n",
              "   Email_Status  \n",
              "0             0  \n",
              "1             0  \n",
              "2             1  \n",
              "3             0  \n",
              "4             0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#first look of our dataset\n",
        "df_orig.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osQgwdzd6Ct7",
        "outputId": "4a045801-2f28-4b38-d21a-1183ccd0650d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 68353 entries, 0 to 68352\n",
            "Data columns (total 12 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Email_ID                   68353 non-null  object \n",
            " 1   Email_Type                 68353 non-null  int64  \n",
            " 2   Subject_Hotness_Score      68353 non-null  float64\n",
            " 3   Email_Source_Type          68353 non-null  int64  \n",
            " 4   Customer_Location          56758 non-null  object \n",
            " 5   Email_Campaign_Type        68353 non-null  int64  \n",
            " 6   Total_Past_Communications  61528 non-null  float64\n",
            " 7   Time_Email_sent_Category   68353 non-null  int64  \n",
            " 8   Word_Count                 68353 non-null  int64  \n",
            " 9   Total_Links                66152 non-null  float64\n",
            " 10  Total_Images               66676 non-null  float64\n",
            " 11  Email_Status               68353 non-null  int64  \n",
            "dtypes: float64(4), int64(6), object(2)\n",
            "memory usage: 6.3+ MB\n"
          ]
        }
      ],
      "source": [
        "#basic info about our data\n",
        "df_orig.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSciyJGe2sSt"
      },
      "source": [
        "#### Data Summary:\n",
        "Our email campaign dataset have 68353 observations and 12 features. Clearly Email_Status is our target variable.\n",
        "\n",
        "Our features:\n",
        "* **Email Id** - It contains the email id's of the customers/individuals\n",
        "* **Email Type** - There are two categories 1 and 2. We can think of them as marketing emails or important updates, notices like emails regarding the business.\n",
        "* **Subject Hotness Score** - It is the email's subject's score on the basis of how good and effective the content is.\n",
        "* **Email Source** - It represents the source of the email like sales and marketing or important admin mails related to the product.\n",
        "* **Email Campaign Type** - The campaign type of the email.\n",
        "* **Total Past Communications** - This column contains the total previous mails from the same source, the number of communications had.\n",
        "* **Customer Location** - Contains demographical data of the customer, the location where the customer resides.\n",
        "* **Time Email sent Category** - It has three categories 1,2 and 3; the time of the day when the email was sent, we can think of it as morning, evening and night time slots.\n",
        "* **Word Count** - The number of words contained in the email.\n",
        "* **Total links** - Number of links in the email.\n",
        "* **Total Images** - Number of images in the email.\n",
        "* **Email Status** - Our target variable which contains whether the mail was ignored, read, acknowledged by the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTf2xZUlZUS3"
      },
      "source": [
        "#### **Data Cleaning and PreProcessing:**\n",
        "\n",
        "When we have raw data, it may contain missing values, NaN values or absurd values. It is necessary to check and handle these values before feeding it to the models, so as to obtain good insights on what the data is trying to say and make great characterisation and prediction which will in turn help improve the business's content. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiPQOB3z2iFf",
        "outputId": "d912ede6-80f8-4a96-fe46-befc202b6387"
      },
      "outputs": [],
      "source": [
        "#get the num of nulls in each column\n",
        "df_orig.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dxZwGz4bct_"
      },
      "source": [
        "We have a lot of nulls in the following columns:\n",
        "* Customer Location\n",
        "* Total Past Communications\n",
        "* Total Links\n",
        "* Total Images\n",
        "\n",
        "\n",
        "But particularly customer location has a lot of them. Since it is a categorical column and it is difficult to just impute them with our understanding of where the customer's location is, we'll see how much it affects our target variable, whether a particular location has anything to do with it or it is not correlated at all and accordingly we can decide on it later on.\n",
        "Let's fill up the null values in other columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "p14xrIDMbTQU",
        "outputId": "71c0127d-e437-4cfc-9a15-8225b9a04b58"
      },
      "outputs": [],
      "source": [
        "#let's see the distribution of Total Past Communications to get what majority of the data tends to so that we can fill it accordingly\n",
        "sns.distplot(x=df_orig['Total_Past_Communications'], hist = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N7gzDnce7L1"
      },
      "source": [
        "We have kind of a normal ditribution for Total Past Communications and it will be fine, if we use mean to fill up the null values of this column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sedSANidkeh"
      },
      "outputs": [],
      "source": [
        "#filling up the null values for total past comm\n",
        "df_orig['Total_Past_Communications'].fillna(df_orig['Total_Past_Communications'].mean(), inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "MvkZzDgxgSxE",
        "outputId": "be9533c4-8d86-4246-fab5-0ce3e5e797c4"
      },
      "outputs": [],
      "source": [
        "#let's see the distribution of Total Links to get what majority of the data tends to so that we can fill it accordingly\n",
        "sns.distplot(x=df_orig['Total_Links'], hist= True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAukBPwmg-ma"
      },
      "source": [
        "It seems like most of the values of the Total Links in the column are between 0-10 and the distribution is skewed on the right. Mode is more robust to outlier effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wcYhmuNgzDN"
      },
      "outputs": [],
      "source": [
        "#filling up the Total Links Column\n",
        "df_orig['Total_Links'].fillna(df_orig['Total_Links'].mode()[0], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "nGF1TN9ciyja",
        "outputId": "68441dbc-d260-4df0-c2e5-25cabec079f1"
      },
      "outputs": [],
      "source": [
        "#total image distribution\n",
        "sns.distplot(x=df_orig['Total_Images'], hist=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TasXvm2ZjW3f"
      },
      "source": [
        "The number of images in most of the emails seems to be 0 or fewer than 3-4. It would be wise to fill the null values with mode values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxXSrM-OjQaR"
      },
      "outputs": [],
      "source": [
        "#filling up the Total Images Column\n",
        "df_orig['Total_Images'].fillna(df_orig['Total_Images'].mode()[0], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbQlUpTWkQYR",
        "outputId": "120ec808-eeae-4754-c0ae-66045fcacfde"
      },
      "outputs": [],
      "source": [
        "#check for duplicates\n",
        "df_orig.duplicated().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Vf6tiaojuV"
      },
      "source": [
        "#### **Exploratory Data Analysis**:\n",
        "\n",
        "\n",
        "Exploratory data analysis is an important part of data analysis. It involves exploring and analyzing the dataset given to find out patterns, trends and conclusions to take better decisions related to the data. In this section, we will be trying to obtain those features which help our emails not get ignored.\n",
        "\n",
        "We will explore every feature against our target variable and analyze it's influence on it.\n",
        "\n",
        "####Categorical Variables:\n",
        "We have six categorical variables Email Type, Email Source, Email Campaign Type, Time Email sent Category, Customer Location and Email Status. We should keep in mind that we have a lot of null values in Customer Location feature and after analysing it's influence on our target variable, we will fill it accordingly or remove it. If a particular location is influencing our target variables and aiding in to getting it ignored or otherwise, it should be filled on a condition (on Email Status) row wise.\n",
        "\n",
        "#### Continuous Variables:\n",
        "Our continuous variables include Subject Hotness Score, Total Past Communications, Word Count, Total Links and Total Images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ph2mKpBd2g14",
        "outputId": "23cfffe0-ba4a-4a75-b30a-133666fce2d4"
      },
      "outputs": [],
      "source": [
        "#starting with categorical variables\n",
        "categorical_variables = ['Email_Type','Email_Source_Type','Customer_Location','Email_Campaign_Type','Time_Email_sent_Category']\n",
        "Target_var = ['Email_Status']\n",
        "\n",
        "for i,value in enumerate(categorical_variables):\n",
        "  ax = sns.countplot(x=df_orig[value], hue=df_orig[Target_var[0]])\n",
        "  unique = len([x for x in df_orig[value].unique() if x==x])\n",
        "  bars = ax.patches\n",
        "  for i in range(unique):\n",
        "      catbars=bars[i:][::unique]\n",
        "      #get height\n",
        "      total = sum([x.get_height() for x in catbars])\n",
        "      #print percentage\n",
        "      for bar in catbars:\n",
        "        ax.text(bar.get_x()+bar.get_width()/2.,\n",
        "                    bar.get_height(),\n",
        "                    f'{bar.get_height()/total:.0%}',\n",
        "                    ha=\"center\",va=\"bottom\")\n",
        "  plt.show()\n",
        "              "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIUFaVEUtmIz"
      },
      "source": [
        "**Observation:** \n",
        "\n",
        "* The email type 1 which may be considered as promotional emails are sent more than email type 2 and hence are read and acknowledged more than the other type otherwise the proportion of ignored, read, acknowledged emails are kind of same in both email types.\n",
        "\n",
        "* Email source type shows kind of a similar pattern for both the categories.\n",
        "\n",
        "* In the customer location feature we can find that irrespective of the location, the percentage ratio of emails being ignored, read and acknowledge are kind of similar. It does not exclusively influence our target variable. It would be better to not consider location as factor in people ignoring, reading or acknowledging our emails. Other factors should be responsible in why people are ignoring the emails not location.\n",
        "\n",
        "* In the Email Campaign Type feature, it seems like in campaign type 1 very few emails were sent but has a very high likelihood of getting read. Most emails were sent under email campaign type 2 and most ignored. Seems like campaign 3 was a success as even when less number of emails were sent under campaign 3, more emails were read and acknowledged.\n",
        "\n",
        "* If we consider 1 annd 3 as morning and night category in time email sent feature, it is obvious to think 2 as middle of the day and as expected there were more emails sent under 2nd category than either of the others, sending emails in the middle of the day could lead to reading and opening the email as people are generally working at that time and they frequently checkup their emails, but it cannot be considered as the major factor in leading to acknowledged emails.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "LWPv5LVnEsdX",
        "outputId": "54d271e6-09cc-4370-c317-20cbaceebebb"
      },
      "outputs": [],
      "source": [
        "#continuous variables\n",
        "#distribution of other continuous features and understanding where the data tends to\n",
        "cont_var = ['Word_Count','Subject_Hotness_Score']\n",
        "for i, value in enumerate(cont_var):\n",
        " sns.distplot(x=df_orig[value], hist = True)\n",
        " plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA3hSDk6Fr2J"
      },
      "source": [
        "We already saw the distribution plots of Total Links, Total Images and Total Past Communications earlier. Here we see that Word Count just as Total Past Communications has a normal distribution. All of the rest are rightly skewed which indicates the presence of outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T0iG2K5WxSvS",
        "outputId": "45c125ec-5cb8-49a7-fc1f-51d6ff61a681"
      },
      "outputs": [],
      "source": [
        "#continuous variables through boxplots\n",
        "cont_var = ['Subject_Hotness_Score', 'Total_Past_Communications','Word_Count','Total_Links','Total_Images']\n",
        "for i, value in enumerate(cont_var):\n",
        " sns.boxplot(x=df_orig['Email_Status'], y= df_orig[value])\n",
        " plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4OCZ97hiRZU"
      },
      "source": [
        "**Observation:**\n",
        "\n",
        "* In the subject hotness score, median of ignored emails was around 1 with a few outliers. Acknowledged emails has the most outliers. It is observed that the Subject_Hotness_Score for read and acknowledged emails are much lower.\n",
        "\n",
        "\n",
        "* Analyzing total past communications, we can see that the more the number of previous emails, the more it leads to read and acknowledged emails. This is just about making connection with your customers.\n",
        "\n",
        "* The more the words in an email, the more it has a tendency to get ignored. Too lengthy emails are getting ignored.\n",
        "\n",
        "* The median is kind of similar in all of the three cases in total links feature with a number of outliers.\n",
        "\n",
        "* More images were there in ignored emails.\n",
        "\n",
        "* There are considerable number of outliers in Subject_Hotness_Score, Total_Links and Total_Images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xksLv2crpwtS"
      },
      "source": [
        "**Correlation:**\n",
        "To get an understanding of how much correlated, positively or negatively our features is with our target variable, we will be creating a correlation matrix.\n",
        "\n",
        "We will be removing Customer location and Email Id features. They will not contribute in deciding whether a customer will ignore, read, acknowledge the email.\n",
        "Let's get to it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cijvg-xjDXkO"
      },
      "outputs": [],
      "source": [
        "#dropping columns\n",
        "columns_to_drop = ['Email_ID','Customer_Location']\n",
        "df = df_orig.drop(columns_to_drop,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 940
        },
        "id": "DGDokflI4fvH",
        "outputId": "806f4a62-a50c-4e76-db37-e904453f12f7"
      },
      "outputs": [],
      "source": [
        "#correlation matrix\n",
        "plt.figure(figsize=(14,9))\n",
        "sns.heatmap(df.corr(), cmap='Blues_r', annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UCJYzOg8NEk"
      },
      "source": [
        "**Observation:**\n",
        "Correlation matrix justifies our earlier hypotheses. Email Campaign Type and Total past communication shows positive correlation with emails being read and acknowledged.\n",
        "Word Count and Subject Hotness score are the most negatives amongst other. We can see multicollinearity involved in Email Campaign Type, Total past communication and Total links, Total Images among others and we will have to deal with it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR_L0t8AFzyh"
      },
      "source": [
        "##Data Manipulation and Feature Engineering:\n",
        "Data manipulation involves manipulating and changing our dataset before feeding it to various clasification machine learning models. This involves keeping important features handling multicollinearity in the dataset, outlier treatment and creating dummy variables if necessary.\n",
        "\n",
        "We have outliers in our dataset as we saw it earlier in data exploration but as the classes are imbalanced and we cannot also risk overfitting, so we will be exploring how many outliers we have in each class and then decide whether we should keep them or get rid of them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1DWyhNuGQtL"
      },
      "source": [
        "**Multicollinearity and Feature Selection:**\n",
        "\n",
        "Multicollinearity occurs when two or more independent continuous features in the dataset are highly correlated and can help predict each other and the dependent variable. This makes it difficult to individually analyse the affect of these individual independent variables on the target or dependent variable.\n",
        "\n",
        "We can quantify multicollinearity using Variance Inflation Factors (VIF).\n",
        "\n",
        "VIF = 1/(1-R^2) \n",
        "The more the value of R^2 is closer to 1 the more, VIF score tends to infinity.\n",
        "VIF starts with 1 and denotes that the variable has no correlation at all.\n",
        "VIF more than 5-10 can be considered as serious case of multicollinearity and can affect prediction models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QMP6NcMII2i"
      },
      "outputs": [],
      "source": [
        "#VIF code\n",
        "def vif_calc(df):\n",
        "  vif = pd.DataFrame()\n",
        "  vif[\"variables\"] = df.columns\n",
        "  vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
        "  return(vif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KshY662oJfWN",
        "outputId": "f2f467fe-85a3-4f95-85a3-91642290cd92"
      },
      "outputs": [],
      "source": [
        "#let's get VIF scores\n",
        "vif_df = vif_calc(df[[i for i in df.describe().columns if i not in categorical_variables + ['Email_Status']]])\n",
        "vif_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4wmB0zELaOq"
      },
      "source": [
        "We can see that only Total Links is higher than 5. Earlier we saw that Total Images and Total Links are highly correlated to each other with a score of 0.75. We can try combining both of these or deleting one of these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "HK_4SbV3UdvD",
        "outputId": "206d4588-20f9-4dab-fa76-4b41630cc4cc"
      },
      "outputs": [],
      "source": [
        "#scatter plot between images and links, shows a linear relationship\n",
        "sns.scatterplot(x=df[\"Total_Images\"],y=df[\"Total_Links\"],hue=df['Email_Status']) #it shows the collinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWshfvWBVdsd"
      },
      "outputs": [],
      "source": [
        "#we can try combining them up\n",
        "df['Total_Img_links'] = df['Total_Images'] + df['Total_Links']\n",
        "df.drop(['Total_Images','Total_Links'],inplace=True,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "fV7J68nqWkAv",
        "outputId": "36f07ad4-c86f-4cd7-94d9-f25d92264d89"
      },
      "outputs": [],
      "source": [
        "#let's check VIF scores\n",
        "vif_df = vif_calc(df[[i for i in df.describe().columns if i not in categorical_variables + ['Email_Status']]])\n",
        "vif_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5SvQuqbWsdX"
      },
      "source": [
        "Now we have our multicollinearity in check!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzmNkQJkXmNZ"
      },
      "source": [
        "\n",
        "\n",
        "**Outliers:**\n",
        "\n",
        "With the help of box-plots, we earlier saw that besides Word Count all our other continuous variables have outliers, but deleting them would lead to loss of information as our target variable is highly imbalanced we need to make sure that we aren't deleting more than 5% of information or data related to the minority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMMneRAHaVkX"
      },
      "outputs": [],
      "source": [
        "#Let's check the number of outliers in each category of diff continuous features\n",
        "cont_var.remove('Word_Count')\n",
        "cont_var.remove('Total_Links')\n",
        "cont_var.remove('Total_Images')\n",
        "cont_var.append('Total_Img_links')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrQTAh-FAdsh",
        "outputId": "c2e4b563-644a-4428-e7ff-b5376aaa5350"
      },
      "outputs": [],
      "source": [
        "#the number of outliers in different features acc to email_status\n",
        "outliers = {}\n",
        "for elem in cont_var:\n",
        "  q_75, q_25 = np.percentile(df.loc[:,elem],[75,25])\n",
        "  IQR = q_75-q_25\n",
        "  max = q_75+(1.5*IQR)\n",
        "  min = q_25-(1.5*IQR)\n",
        "  outlier_list=[]\n",
        "  outlier_list=df.loc[df[elem] < min]['Email_Status'].tolist()\n",
        "  outlier_list.append(df.loc[df[elem] > max]['Email_Status'].tolist()) \n",
        "  outliers[elem]={}\n",
        "  for i in outlier_list[0]:\n",
        "      outliers[elem][i] = outliers[elem].get(i,0) + 1\n",
        "print(outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59bqrsu2vwpr"
      },
      "source": [
        "We calculated the number of outliers with respect to the individual classes of our target variable. The minority class in our target variable is 1 and 2. But when we get rid of outliers we should check that we aren't deleting more than 5% of useful information related to minority class. Otherwise, the model will not be able to classify our minority classes correctly having lack of information. Let's check the percentage of outliers in minority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHw6EAV4ocvk",
        "outputId": "55efeb41-baf6-490b-ff08-380aa410b326"
      },
      "outputs": [],
      "source": [
        "df['Email_Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzGzgwGWk2kV",
        "outputId": "45e1a2b3-c9ea-42f1-e884-ffc1b759def0"
      },
      "outputs": [],
      "source": [
        "#percentage of outliers in minority class\n",
        "minority_outliers = 0  \n",
        "majority_outliers = 0\n",
        "for col in cont_var:\n",
        "  minority_outliers += outliers[col][1]\n",
        "  minority_outliers += outliers[col][2]\n",
        "  majority_outliers += outliers[col][0]\n",
        "\n",
        "total_min = df['Email_Status'].value_counts()[1] + df['Email_Status'].value_counts()[2]\n",
        "total_maj = df['Email_Status'].value_counts()[0]\n",
        "\n",
        "min_per = (minority_outliers/total_min)*100   #number of outliers in minority classes by total number minority classes\n",
        "maj_per = (majority_outliers/total_maj)*100  #number of outliers in majority class by total number of majority class\n",
        "total_out = ((minority_outliers+majority_outliers)/(total_min+total_maj))*100\n",
        "print(f'The percentage of outliers in minority classes is {min_per}')\n",
        "print(f'The percentage of outliers in majority class is {maj_per}')\n",
        "print(f'The percentage of total outliers are {total_out}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwWwwCDqti70",
        "outputId": "685a7b4c-7a8e-41e5-cd5e-6c8ce1c24fd1"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7luYHv-uU7i",
        "outputId": "0e96e707-b056-46f1-ef32-f1c984337641"
      },
      "outputs": [],
      "source": [
        "df['Email_Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQjmFYvNqJrT"
      },
      "outputs": [],
      "source": [
        "#deleting majority outliers\n",
        "for elem in cont_var:\n",
        "  q_low = df[elem].quantile(0.01)\n",
        "  q_hi  = df[elem].quantile(0.99)\n",
        "  df = df.drop(df[(df[elem] > q_hi) &  (df['Email_Status']==0)].index)\n",
        "  df = df.drop(df[(df[elem] < q_low) & (df['Email_Status']==0)].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLhS9BP8tl0W",
        "outputId": "b02859c0-e42c-4566-9c01-564dbd7da60c"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1q5Z63dudHK",
        "outputId": "408e2f6e-e5c3-49d5-ac54-f730fa791ac9"
      },
      "outputs": [],
      "source": [
        "df['Email_Status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9g7SkQQrNkf"
      },
      "source": [
        "We have more than 5% outliers in minority section and hence to avoid lack of information, we decide against deleting them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bpgt0oyjW0I"
      },
      "source": [
        "**Feature Scaling**\n",
        "\n",
        "Feature Scaling is a technique to standardize the independent features present in the data in a fixed range. It is done to prevent biased nature of machine learning algorithms towards features with greater values and scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usTXtwA6sSDU"
      },
      "outputs": [],
      "source": [
        "#let's add back word count\n",
        "cont_var.append('Word_Count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cont_var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "lg7pEZXBC1Df",
        "outputId": "df271865-f645-4076-d5ff-5d7abbf8df55"
      },
      "outputs": [],
      "source": [
        "#feature scaling of numerical variables\n",
        "for elem in cont_var:\n",
        "  df[elem] = (df[elem] - df[elem].mean()) / (df[elem].std())\n",
        "\n",
        "df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyTQ6FqY7qkA"
      },
      "source": [
        "**One hot encoding**\n",
        "\n",
        "For categorical variables where no such ordinal relationship exists, the integer encoding is not enough. We have categorical data integer encoded with us, but assuming a natural order and allowing this data to the model may result in poor performance. If the\n",
        "categorical variable is an output variable, you may also want to convert predictions by the model back into a categorical form in order to present them or use them in some application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ01djW_9PWE"
      },
      "outputs": [],
      "source": [
        "#getting dummy variables for categorical data\n",
        "categorical_variables.remove('Customer_Location')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP34qDpg9z69",
        "outputId": "eb5e1aeb-8624-4fd8-d092-95f6e3ed4593"
      },
      "outputs": [],
      "source": [
        "#categorical var that need to be encoded\n",
        "categorical_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ZQ8D-GFY938o",
        "outputId": "74d0373d-1c2d-4a71-aa74-bb9ad307c33c"
      },
      "outputs": [],
      "source": [
        "#creating dummy variables\n",
        "df = pd.get_dummies(df,columns=categorical_variables)\n",
        "# as some features had binary categories, we are going to delete one of them to keep it binary encoded and have less columns\n",
        "df.drop('Email_Type_2',axis=1,inplace=True)\n",
        "df.drop('Email_Source_Type_2',axis=1,inplace=True)\n",
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he2aXMVywKrZ",
        "outputId": "da96c2c8-2da3-4cef-99fd-86c4109f96ca"
      },
      "outputs": [],
      "source": [
        "#shape\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "yTK54GVNHQuV",
        "outputId": "826771eb-50cc-4fc7-e687-e1ca06b7cc9b"
      },
      "outputs": [],
      "source": [
        "#Email_Status should be the last col\n",
        "columns=list(df.columns)\n",
        "columns.remove('Email_Status')\n",
        "columns.append('Email_Status')\n",
        "df=df[columns]\n",
        "df.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y-0k6P1ayYu"
      },
      "source": [
        "## **Modelling**:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiADri9Ra8G9"
      },
      "source": [
        "**Train-Test Split**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDiS1QwrlLie",
        "outputId": "d5bc5c2b-40a7-4bbe-a98e-3f064e14bba7"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waHuevnhcLxP",
        "outputId": "ef7ce7a6-5563-41d5-83eb-512623c9827d"
      },
      "outputs": [],
      "source": [
        "#X and Y \n",
        "X = df.drop('Email_Status',axis=1)\n",
        "y = df['Email_Status']\n",
        "print(f'Shape of X: {X.shape}')\n",
        "print(f'Shape of Y: {y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWQ_MlXYbtjS"
      },
      "outputs": [],
      "source": [
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y) \n",
        "#we need to stratify to get same proprtion of classes in both the sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFuvAdaZgngv"
      },
      "source": [
        "#### **Handling Class Imbalance**\n",
        "\n",
        "In the exploratory data analysis, we clearly saw that the number of emails being ignored was a lot more than being read and acknowledged. \n",
        "This imbalance in the class, can lead to biased classification towards ignored emails. We can handle it with Oversampling and Undersampling.\n",
        "\n",
        "First, we will go with Random Undersampling and check the results for various models that we will be testing and then with SMOTE. This technique generates synthetic data for the minority class. Lastly, we will analyze which method works for the best for our dataset.\n",
        "\n",
        "Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset.\n",
        "\n",
        "SMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "uCtEaHuNCwxL",
        "outputId": "cf4b84e0-4f27-484a-9fab-7fd221192624"
      },
      "outputs": [],
      "source": [
        "#count plot for target variable\n",
        "#visualizing our imbalanced dataset\n",
        "ax = sns.countplot(x=df['Email_Status'])\n",
        "totals = []\n",
        "for i in ax.patches:\n",
        "    totals.append(i.get_height())\n",
        "\n",
        "total = sum(totals)\n",
        "\n",
        "for i in ax.patches:\n",
        "    ax.text(i.get_x() - .01, i.get_height() + .5, \\\n",
        "          str(round((i.get_height()/total)*100, 2))+'%', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgIuVRaLDTUF"
      },
      "source": [
        "Only 3% of observations are classified as acknowledged emails and 80% are ignored emails. This will create a bias in favour of ignored emails in the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj_VFUebNVfh",
        "outputId": "b37beca5-c26c-44ba-deef-8373ab7397e3"
      },
      "outputs": [],
      "source": [
        "df['Email_Status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgQGWGdEXAIX"
      },
      "source": [
        "We will be applying the Random Under Sampler and SMOTE algorithms to balance our classes on the train set only, so that the model doesn't catch up to the test set at all.\n",
        "Before balancing, we made sure the train split has class distribution as same as the main dataset by using stratify while splitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oANMmJMrSRRq"
      },
      "source": [
        "**Random Undersampling:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSPQtrhVURJk",
        "outputId": "cc47f1b4-19d1-4a55-fdbc-dc48839586ca"
      },
      "outputs": [],
      "source": [
        "#importing random under sampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "#resample\n",
        "rus = RandomUnderSampler(random_state=42, replacement=True)\n",
        "x_train_rus, y_train_rus = rus.fit_resample(X_train,y_train)\n",
        "\n",
        "#print shape\n",
        "print('Original dataset shape:', len(y_train))\n",
        "print('Resampled dataset shape', len(y_train_rus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "lU1iZIK9Yc44",
        "outputId": "f3b44484-386b-4054-a831-51eef3470cc5"
      },
      "outputs": [],
      "source": [
        "#visualization of resampled data\n",
        "def resampled_data_visual(y_train_rus):\n",
        "  counter = Counter(y_train_rus)\n",
        "  for key,value in counter.items():\n",
        "    per = value / len(y_train_rus) * 100\n",
        "    print('Class=%d, n=%d (%.3f%%)' % (key, value, per))\n",
        "  # plot the distribution\n",
        "  plt.bar(counter.keys(), counter.values())\n",
        "  plt.show()\n",
        "\n",
        "resampled_data_visual(y_train_rus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJRJmVSMJtpd"
      },
      "source": [
        "**SMOTE:** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2vGL4wvMFU-",
        "outputId": "8f975abd-f7c0-469c-f608-4b2e8257ab75"
      },
      "outputs": [],
      "source": [
        "#SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE()\n",
        "\n",
        "# fit predictor and target variable\n",
        "x_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "print('Original dataset shape', len(y_train))\n",
        "print('Resampled dataset shape', len(y_train_smote))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "4p_zV9H3NO_-",
        "outputId": "66232a8c-d680-41f2-cd98-8316524d73f8"
      },
      "outputs": [],
      "source": [
        "#visualization of resampled data\n",
        "resampled_data_visual(y_train_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXI0QsaOU2-2"
      },
      "source": [
        "#### **Logistic Regression:**\n",
        "\n",
        "Logistic Regression is a classification algorithm that predicts the probability of an outcome that can have only two values. \n",
        "\n",
        "Multinomial logistic regression is an extension of logistic regression that adds native support for multi-class classification problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky498MndOlPr",
        "outputId": "1b356c61-585d-4ace-eb19-32cc90d3bebb"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#fitting Undersampling\n",
        "logistic_rus = LogisticRegression(class_weight='balanced',multi_class='multinomial', solver='lbfgs')\n",
        "logistic_rus.fit(x_train_rus, y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-pis9qvVdy_",
        "outputId": "cc7a06e5-ecb5-40f1-a9d4-dc526acab19b"
      },
      "outputs": [],
      "source": [
        "#fitting on smote\n",
        "logistic_smote = LogisticRegression(class_weight='balanced',multi_class='multinomial', solver='lbfgs')\n",
        "logistic_smote.fit(x_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB2SCjwyWUvP"
      },
      "outputs": [],
      "source": [
        "#Columns needed to compare metrics\n",
        "comparison_columns = ['Model_Name', 'Train_Accuracy', 'Train_Recall', 'Train_Precision', 'Train_F1score', 'Train_AUC' ,'Test_Accuracy', 'Test_Recall', 'Test_Precision', 'Test_F1score', 'Test_AUC']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUrpDlPfaBTS"
      },
      "outputs": [],
      "source": [
        "#Function to evaluate the model\n",
        "\n",
        "def model_evaluation(model_name_RUS,model_name_SMOTE,model_var_rus, model_var_smote, x_train_rus, y_train_rus, x_train_smote, y_train_smote, X_test, y_test):\n",
        "  ''' This function predicts and evaluates various models for clasification for Random Undersampling and SMOTE algorithms, visualizes results \n",
        "      and creates a dataframe that compares the various models.'''\n",
        "  \n",
        "  #Making predictions random undersampling\n",
        "  y_pred_rus_train = model_var_rus.predict(x_train_rus)\n",
        "  y_pred_rus_test = model_var_rus.predict(X_test)\n",
        "  #probs\n",
        "  train_rus_proba = model_var_rus.predict_proba(x_train_rus)\n",
        "  test_rus_proba = model_var_rus.predict_proba(X_test)\n",
        "\n",
        "  #Making predictions smote\n",
        "  y_pred_smote_train = model_var_smote.predict(x_train_smote)\n",
        "  y_pred_smote_test = model_var_smote.predict(X_test)\n",
        "  #probs\n",
        "  train_sm_proba = model_var_smote.predict_proba(x_train_smote)\n",
        "  test_sm_proba = model_var_smote.predict_proba(X_test)\n",
        "\n",
        "  #Evaluation \n",
        "  #Accuracy RUS\n",
        "  accuracy_rus_train = accuracy_score(y_train_rus,y_pred_rus_train)\n",
        "  accuracy_rus_test = accuracy_score(y_test,y_pred_rus_test)\n",
        "  #Accuracy SMOTE\n",
        "  accuracy_smote_train = accuracy_score(y_train_smote,y_pred_smote_train)\n",
        "  accuracy_smote_test = accuracy_score(y_test,y_pred_smote_test)\n",
        "\n",
        "  #Confusion Matrix RUS\n",
        "  cm_rus_train = confusion_matrix(y_train_rus,y_pred_rus_train)\n",
        "  cm_rus_test = confusion_matrix(y_test,y_pred_rus_test)\n",
        "  #Confusion Matrix SMOTE\n",
        "  cm_smote_train = confusion_matrix(y_train_smote,y_pred_smote_train)\n",
        "  cm_smote_test = confusion_matrix(y_test,y_pred_smote_test)\n",
        "\n",
        "  #Recall RUS\n",
        "  train_recall_rus = recall_score(y_train_rus,y_pred_rus_train, average='weighted')\n",
        "  test_recall_rus = recall_score(y_test,y_pred_rus_test, average='weighted')\n",
        "  #Recall SMOTE\n",
        "  train_recall_smote = recall_score(y_train_smote,y_pred_smote_train, average='weighted')\n",
        "  test_recall_smote = recall_score(y_test,y_pred_smote_test, average='weighted')\n",
        "\n",
        "  #Precision RUS\n",
        "  train_precision_rus = precision_score(y_train_rus,y_pred_rus_train, average='weighted')\n",
        "  test_precision_rus = precision_score(y_test,y_pred_rus_test, average='weighted')\n",
        "  #Precision SMOTE\n",
        "  train_precision_smote = precision_score(y_train_smote,y_pred_smote_train, average='weighted')\n",
        "  test_precision_smote = precision_score(y_test,y_pred_smote_test, average='weighted')\n",
        "\n",
        "  #F1 Score RUS\n",
        "  train_f1_rus = f1_score(y_train_rus,y_pred_rus_train, average='weighted')\n",
        "  test_f1_rus = f1_score(y_test,y_pred_rus_test, average='weighted')\n",
        "  #F1 Score SMOTE\n",
        "  train_f1_smote = f1_score(y_train_smote,y_pred_smote_train, average='weighted')\n",
        "  test_f1_smote = f1_score(y_test,y_pred_smote_test, average='weighted')\n",
        "\n",
        "  #ROC-AUC RUS\n",
        "  train_auc_rus = roc_auc_score(y_train_rus,train_rus_proba,average='weighted',multi_class = 'ovr')\n",
        "  test_auc_rus = roc_auc_score(y_test,test_rus_proba,average='weighted',multi_class = 'ovr')\n",
        "  #ROC-AUC SMOTE\n",
        "  train_auc_smote = roc_auc_score(y_train_smote,train_sm_proba,average='weighted',multi_class = 'ovr')\n",
        "  test_auc_smote = roc_auc_score(y_test,test_sm_proba,average='weighted',multi_class = 'ovr')\n",
        "\n",
        "  #Visualising Results RUS\n",
        "  print(\"----- Evaluation on Random Undersampled data -----\" + str(model_name_RUS) + \"------\")\n",
        "  print(\"--------------Test data ---------------\\n\")\n",
        "  print(\"Confusion matrix \\n\")\n",
        "  print(cm_rus_test)\n",
        "  print(classification_report(y_test,y_pred_rus_test))\n",
        "\n",
        "  #create ROC curve\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  thresh ={}\n",
        "  no_of_class=3\n",
        "  for i in range(no_of_class):    \n",
        "      fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, test_rus_proba[:,i], pos_label=i)\n",
        "  plt.plot(fpr[0], tpr[0], linestyle='--',color='blue', label='Class 0 vs Others'+\"AUC=\"+str(test_auc_rus))\n",
        "  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Others'+\"AUC=\"+str(test_auc_rus))\n",
        "  plt.plot(fpr[2], tpr[2], linestyle='--',color='orange', label='Class 2 vs Others'+\"AUC=\"+str(test_auc_rus))\n",
        "  plt.title('Multiclass ROC curve of ' + str(model_name_RUS))\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Visualising Results SMOTE\n",
        "  print(\"----- Evaluation on SMOTE data -------\" + str(model_name_SMOTE) + '-----')\n",
        "  print(\"---------------Test data ---------------\\n\")\n",
        "  print(\"Confusion matrix \\n\")\n",
        "  print(cm_smote_test)\n",
        "  print(classification_report(y_test,y_pred_smote_test))\n",
        "\n",
        " \n",
        "  #create ROC curve\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  thresh ={}\n",
        "  no_of_class=3\n",
        "  for i in range(no_of_class):    \n",
        "      fpr[i], tpr[i], thresh[i] = metrics.roc_curve(y_test, test_sm_proba[:,i], pos_label=i)\n",
        "  plt.plot(fpr[0], tpr[0], linestyle='--',color='blue', label='Class 0 vs Others'+\" AUC=\"+str(test_auc_smote))\n",
        "  plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Others'+\" AUC=\"+str(test_auc_smote))\n",
        "  plt.plot(fpr[2], tpr[2], linestyle='--',color='orange', label='Class 2 vs Others'+\" AUC=\"+str(test_auc_smote))\n",
        "  plt.title('Multiclass ROC curve of '+ str(model_name_SMOTE))\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.legend(loc=4)\n",
        "  plt.show()\n",
        "\n",
        "  #Saving our results\n",
        "  global comparison_columns\n",
        "  metric_scores_rus = [model_name_RUS,accuracy_rus_train,train_recall_rus,train_precision_rus,train_f1_rus,train_auc_rus,accuracy_rus_test,test_recall_rus,test_precision_rus,test_f1_rus,test_auc_rus]\n",
        "  final_dict_rus = dict(zip(comparison_columns,metric_scores_rus))\n",
        "\n",
        "  metric_scores_smote = [model_name_SMOTE,accuracy_smote_train,train_recall_smote,train_precision_smote,train_f1_smote,train_auc_smote,accuracy_smote_test,test_recall_smote,test_precision_smote,test_f1_smote,test_auc_smote]\n",
        "  final_dict_smote = dict(zip(comparison_columns,metric_scores_smote))\n",
        "\n",
        "  dict_list = [final_dict_rus, final_dict_smote]\n",
        "  return dict_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5kyhMGYe24v"
      },
      "outputs": [],
      "source": [
        "#function to create the comparison table\n",
        "final_list = []\n",
        "def add_list_to_final_df(dict_list):\n",
        "  global final_list\n",
        "  for elem in dict_list:\n",
        "    final_list.append(elem)\n",
        "  global comparison_df\n",
        "  comparison_df = pd.DataFrame(final_list, columns= comparison_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agZnvM9Zd9Rd",
        "outputId": "5614ceb5-0f28-4e19-889c-427128570ea7"
      },
      "outputs": [],
      "source": [
        "#Let's evaluate logistic reg\n",
        "logistic_reg_list = model_evaluation('LogisticReg RUS','LogisticReg SMOTE',logistic_rus, logistic_smote, x_train_rus, y_train_rus, x_train_smote, y_train_smote, X_test, y_test)\n",
        "logistic_reg_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZB4MQHQXUg6"
      },
      "outputs": [],
      "source": [
        "#adding result to final list\n",
        "add_list_to_final_df(logistic_reg_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "nhhghuFFZ5YV",
        "outputId": "023f5833-359d-42ec-ad0d-661d4968d99e"
      },
      "outputs": [],
      "source": [
        "#Taking a look of our final comparison dataframe\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOuRxDqNjb4q"
      },
      "source": [
        "####**Decison Tree Model:**\n",
        "Decision Trees are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0eaB0rzbFrO"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDaipRssnfRS",
        "outputId": "4b14bd5c-b18e-486a-a306-040f1b72ac8a"
      },
      "outputs": [],
      "source": [
        "#Classifier RUS\n",
        "dt_rus = DecisionTreeClassifier()\n",
        "dt_rus.fit(x_train_rus,y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mhqVN1Qn9Wv",
        "outputId": "ed413581-632c-47f9-9e0b-bfe0c18a59d5"
      },
      "outputs": [],
      "source": [
        "#Classifier SMOTE\n",
        "dt_smote = DecisionTreeClassifier()\n",
        "dt_smote.fit(x_train_smote,y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lySiU03WoFod",
        "outputId": "f85f839a-9234-437c-dda7-c2fee9805656"
      },
      "outputs": [],
      "source": [
        "dt_eval_list = model_evaluation('Decision Tree RUS', 'Decision Tree SMOTE', dt_rus, dt_smote, x_train_rus, y_train_rus, x_train_smote, y_train_smote, X_test, y_test)\n",
        "dt_eval_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "FbCjISrKouRW",
        "outputId": "62886fae-51b5-4001-8efe-8db8f33eeafc"
      },
      "outputs": [],
      "source": [
        "#adding list\n",
        "add_list_to_final_df(dt_eval_list)\n",
        "#Taking a look of our final comparison dataframe\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTzKC6HsrAd6"
      },
      "source": [
        "**Observation:** Clearly Decision Tree models are overfitting. Both the datasets, whether undersampled or oversampled with SMOTE are working really well on train data but not on test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCXHvQn3W8x5"
      },
      "source": [
        "#### **Random Forest Model:**\n",
        "\n",
        "To prevent overfitting, we will be building random forest model. Random forest builds multiple decision trees and merges them together to get a more accurate and stable prediction. The ensemble models with only one tree will overfit to data as well because it is the same as a single decision tree. When we add trees to the Random Forest then the tendency to overfitting decreases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUsZTR21pEac"
      },
      "outputs": [],
      "source": [
        "#importing library\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFkrbYmiXXVS",
        "outputId": "9616111c-a21e-4607-c787-65dfef5adf5f"
      },
      "outputs": [],
      "source": [
        "#RUS\n",
        "rf_rus = RandomForestClassifier(random_state=42, max_depth=5, n_estimators=100, oob_score=True)\n",
        "rf_rus.fit(x_train_rus,y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8tL9Vd0aJ-y",
        "outputId": "9f2d0aaf-5dc5-431c-abef-8458aba9f5dd"
      },
      "outputs": [],
      "source": [
        "#SMOTE\n",
        "rf_smote = RandomForestClassifier(random_state=42, max_depth=5, n_estimators=100, oob_score=True)\n",
        "rf_smote.fit(x_train_smote,y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_qUwGNg-aa1U",
        "outputId": "744eeab3-c3fd-4cc2-81a9-d57e7197c613"
      },
      "outputs": [],
      "source": [
        "#Random Forest Evaluation\n",
        "rf_eval_list = model_evaluation('Random Forest RUS', 'Random Forest SMOTE', rf_rus, rf_smote, x_train_rus, y_train_rus, x_train_smote, y_train_smote, X_test, y_test)\n",
        "rf_eval_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "E8FF1J8QbN-y",
        "outputId": "a1bc70c6-2658-48c6-8fc9-26c9f1994cc9"
      },
      "outputs": [],
      "source": [
        "#adding list\n",
        "add_list_to_final_df(rf_eval_list)\n",
        "#Taking a look of our final comparison dataframe\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64uH0G7bd5Oq"
      },
      "source": [
        "**Random Forest Hyperparameter Tuning:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Y5PvoYJbh43"
      },
      "outputs": [],
      "source": [
        "#classifier\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVJuK_2veNdH"
      },
      "outputs": [],
      "source": [
        "#Parameter dictionary\n",
        "params = {'max_depth': [3,5,10,20],'min_samples_leaf': [5,10,20,50,100],'n_estimators': [10,25,30,50,100,200]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17pvqfdcecrA"
      },
      "outputs": [],
      "source": [
        "#Grid Search to get the best parameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=params, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERk2IHd0ht7J",
        "outputId": "a069b518-5776-4fa7-e83d-783cd439633b"
      },
      "outputs": [],
      "source": [
        "#Fitting RUS to grid search\n",
        "grid_search.fit(x_train_rus,y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TZMNOudiGsU"
      },
      "outputs": [],
      "source": [
        "#optimal model\n",
        "rf_tuned_rus = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVdcO5HkjLoq",
        "outputId": "fc2fb920-e71f-463c-be89-10ecc78f6fd6"
      },
      "outputs": [],
      "source": [
        "#Fitting SMOTE\n",
        "grid_search_smote = GridSearchCV(estimator=rf, param_grid=params, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")\n",
        "grid_search_smote.fit(x_train_smote,y_train_smote)\n",
        "#optimal smote model\n",
        "rf_tuned_smote = grid_search_smote.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_smote.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Rs3MefTbj1Ak",
        "outputId": "4974a25b-4e37-4a50-904e-58de1f44379c"
      },
      "outputs": [],
      "source": [
        "#Model Evaluation for Random Forest Hyperparameter \n",
        "rf_tuned_list = model_evaluation('RandomF Tuned RUS', 'RandomF Tuned SMOTE', rf_tuned_rus, rf_tuned_smote,x_train_rus, y_train_rus, x_train_smote, y_train_smote, X_test, y_test)\n",
        "rf_tuned_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "68joHuCHlRiS",
        "outputId": "3dfa60e2-0c1d-4ed7-e43e-63d5171b75d7"
      },
      "outputs": [],
      "source": [
        "#adding list\n",
        "add_list_to_final_df(rf_tuned_list)\n",
        "#Taking a look of our final comparison dataframe\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cYi3w8bl_-g"
      },
      "source": [
        "**Random Forest HyperParameter Tuned Feature Importance:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seWplJabmLS0"
      },
      "outputs": [],
      "source": [
        "#feature importance by random forest \n",
        "feature_imp = pd.DataFrame({\"Variable\": x_train_smote.columns,\"Importance\": rf_tuned_smote.feature_importances_})\n",
        "feature_imp.sort_values(by=\"Importance\", ascending=False, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "_YP4LFXic66h",
        "outputId": "ad5d6778-bd91-475a-9b8c-6a890c67f902"
      },
      "outputs": [],
      "source": [
        "feature_imp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "5WZ4447LcMDm",
        "outputId": "a0fe5980-7dcc-494c-af7e-82812a6edc14"
      },
      "outputs": [],
      "source": [
        "#visualisation\n",
        "sns.barplot(x=feature_imp['Importance'],y= feature_imp['Variable'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZtrQohY8QzX"
      },
      "outputs": [],
      "source": [
        "#drop unrelated features\n",
        "x_train_smote1 = x_train_smote.drop(['Time_Email_sent_Category_3','Time_Email_sent_Category_1','Time_Email_sent_Category_2'],axis=1)\n",
        "x_train_rus1 = x_train_rus.drop(['Time_Email_sent_Category_3','Time_Email_sent_Category_1','Time_Email_sent_Category_2'],axis=1)\n",
        "X_test1 = X_test.drop(['Time_Email_sent_Category_3','Time_Email_sent_Category_1','Time_Email_sent_Category_2'],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvPJunEU9dlM"
      },
      "source": [
        "#### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sANVdDZ7-tzD",
        "outputId": "f9257cde-495d-4c3e-bea6-5913a6e155c8"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Grid Search to get the best parameters\n",
        "grid_search_rus = GridSearchCV(estimator=rf, param_grid=params, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")\n",
        "#Fitting RUS to grid search\n",
        "grid_search_rus.fit(x_train_rus1,y_train_rus)\n",
        "#optimal model\n",
        "rf_tuned_rus1 = grid_search_rus.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CWBrl3y_qYZ",
        "outputId": "b8e8913c-4019-4e02-e3b6-7ca452d2d3b3"
      },
      "outputs": [],
      "source": [
        "#Fitting SMOTE\n",
        "grid_search_smote1 = GridSearchCV(estimator=rf, param_grid=params, cv = 4, n_jobs=-1, verbose=1, scoring=\"f1_weighted\")\n",
        "grid_search_smote1.fit(x_train_smote1,y_train_smote)\n",
        "#optimal smote model\n",
        "rf_tuned_smote1 = grid_search_smote1.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train_smote1.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_tuned_smote1 = grid_search_smote1.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_tuned_smote1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gyqgHK8B8_gX",
        "outputId": "2d9158ab-7277-49f1-9326-14c8fd78acb7"
      },
      "outputs": [],
      "source": [
        "#Model Evaluation for Random Forest Hyperparameter with feature selection  \n",
        "rf_tuned_list1 = model_evaluation('RandomF Tuned RUS FSel', 'RandomF Tuned SMOTE FSel', rf_tuned_rus1, rf_tuned_smote1,x_train_rus1, y_train_rus, x_train_smote1, y_train_smote, X_test1, y_test)\n",
        "rf_tuned_list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "lPvXlUUoADFr",
        "outputId": "91f57669-47ef-42fb-d57f-0a4ed407bd8b"
      },
      "outputs": [],
      "source": [
        "#adding list\n",
        "add_list_to_final_df(rf_tuned_list1)\n",
        "#Taking a look of our final comparison dataframe\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVrObI5cv7rV"
      },
      "source": [
        "#### **XG Boost Model:**\n",
        "\n",
        "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. The two reasons to use XGBoost are also the two goals of the project:\n",
        "* Execution Speed.\n",
        "* Model Performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWCUUnsexxfT"
      },
      "outputs": [],
      "source": [
        "#importing\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIdhBMCvzc9Y",
        "outputId": "950c9b14-9fda-483d-f94c-8e77ca273844"
      },
      "outputs": [],
      "source": [
        "#fitting rus\n",
        "xgb_rus = XGBClassifier(n_estimators=100,max_depth=12,min_samples_leaf=20,min_samples_split=30)\n",
        "xgb_rus.fit(x_train_rus,y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J58ZbFjw0IDj",
        "outputId": "c5ea3e09-da5b-42fc-cf4b-1ed58cfd38c8"
      },
      "outputs": [],
      "source": [
        "#fitting smote\n",
        "xgb_smote = XGBClassifier(n_estimators=100,max_depth=12,min_samples_leaf=20,min_samples_split=30)\n",
        "xgb_smote.fit(x_train_smote,y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tBWJVhvT0PK1",
        "outputId": "c7bd1c8a-f6f6-4c26-90ab-63a1f63285a3"
      },
      "outputs": [],
      "source": [
        "#model evaluation of XGB\n",
        "xgb_eval_list = model_evaluation('XGB RUS', 'XGB SMOTE',xgb_rus, xgb_smote,x_train_rus, y_train_rus, x_train_smote, y_train_smote, X_test, y_test)\n",
        "xgb_eval_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "mnEXLye11YFr",
        "outputId": "100ae4f1-b6a0-4c6f-fff6-2cc98d5d01dc"
      },
      "outputs": [],
      "source": [
        "#visualising feature importance of XGB\n",
        "feature_imp_xgb = pd.DataFrame({\"Variable\": x_train_smote.columns,\"Importance\": xgb_smote.feature_importances_})\n",
        "feature_imp_xgb.sort_values(by=\"Importance\", ascending=False, inplace = True)\n",
        "sns.barplot(x=feature_imp_xgb['Importance'], y= feature_imp_xgb['Variable'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "9dmUDOqj0lsJ",
        "outputId": "9724376f-ea10-486f-cb58-4d570c96a3aa"
      },
      "outputs": [],
      "source": [
        "#adding list\n",
        "add_list_to_final_df(xgb_eval_list)\n",
        "#Taking a look of our final comparison dataframe\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgMFAu86qQv"
      },
      "source": [
        "## **Conclusion:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMOevMWTBP6k"
      },
      "source": [
        "**Evaluation Metrics:**\n",
        "\n",
        "There is a number of model evaluation metrics to choose from but since our dataset was highly imbalanced, it is critical to understand which metric should be evaluated to understand the model performance.\n",
        "\n",
        "* Accuracy- Accuracy simply measures how often the classifier correctly predicts. We can define accuracy as the ratio of the number of correct predictions and the total number of predictions. Accuracy is useful when the target class is well balanced but is not a good choice for the unbalanced classes, because if the model poorly predicts every observation as of the majority class, we are going to get a pretty high accuracy.\n",
        "\n",
        "* Confusion Matrix - It is a performance measurement criteria for the machine learning classification problems where we get a table with a combination of predicted and actual values.\n",
        "\n",
        "* Precision - Precision for a label is defined as the number of true positives divided by the number of predicted positives.\n",
        "\n",
        "* Recall - Recall for a label is defined as the number of true positives divided by the total number of actual positives. Recall explains how many of the actual positive cases we were able to predict correctly with our model.\n",
        "\n",
        "* F1 Score - It's actually the harmonic mean of Precision and Recall. It is maximum when Precision is equal to Recall.\n",
        "\n",
        "* AUC ROC - The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes. When AUC is 0.5, the classifier is not able to distinguish between the classes and when it's closer to 1,the more good it becomes in distingushing them.\n",
        "\n",
        "\n",
        "**So among all the above metrics, which metric should be prioritised in comparing the performance of our various models? That's the major question here as we have a multiclass classification problem, where the problem statement just asks us to track and classify between ignored, read and acknowledged classes, we can not decide here what we want to prioritise in terms of classification, we just want to correctly classify and characterize accordingly. On top of that our data is highly imbalanced, which we tried to encounter in the ways possible.**\n",
        "\n",
        "**When we have a high class imbalance, we'll choose the F1 score because a high F1 score considers both precision and recall. To get a high F1, both false positives and false negatives must be low. The F1 score depends on how highly imbalanced our dataset is!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "IjLwPBzB7WQw",
        "outputId": "02f25139-6314-499c-ae38-7986ee11002c"
      },
      "outputs": [],
      "source": [
        "#visualising our comparison df for f1 score\n",
        "sns.barplot(y=comparison_df['Model_Name'], x = comparison_df['Test_F1score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "JpuLCK7Eopp2",
        "outputId": "b82d374d-d471-42f2-ae54-3fa51084a3aa"
      },
      "outputs": [],
      "source": [
        "#visualising for auc\n",
        "sns.barplot(y=comparison_df['Model_Name'], x = comparison_df['Test_AUC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "fpqVT1P9LpiQ",
        "outputId": "71c4c160-94f9-4a5d-fb32-9b81de43d403"
      },
      "outputs": [],
      "source": [
        "#sorting values\n",
        "comparison_df.sort_values(by=[\"Test_F1score\",'Test_AUC'], ascending=(False,False), inplace = True, ignore_index = True)\n",
        "comparison_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select the top 3 models based on Test_F1score\n",
        "top_models = comparison_df.nlargest(3, 'Test_F1score')\n",
        "top_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''import pickle\n",
        "\n",
        "# Assuming you have the models stored in a dictionary\n",
        "models_dict = {\n",
        "    'model_xgb_stome': xgb_smote,\n",
        "    'model_ramdomF_tuned_smote_FSel': rf_tuned_smote1,\n",
        "    'model_randomF_tuned_smote': rf_tuned_smote\n",
        "}\n",
        "\n",
        "# Pickle the top 3 models\n",
        "for model_name in top_models['Model_Name']:\n",
        "    model = models_dict[model_name]\n",
        "    with open(f'{model_name}.pkl', 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "# Store the names of the top 3 models\n",
        "top_model_names = top_models['Model_Name'].tolist()\n",
        "print(\"Top 3 model names:\", top_model_names)'''\n",
        "\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Assuming you have the models stored in a dictionary\n",
        "models_dict = {\n",
        "    'model_xgb_smote': xgb_smote,  # Replace with your actual model object\n",
        "    'model_randomF_tuned_smote_FSel': rf_tuned_smote1,  # Replace with your actual model object\n",
        "    'model_randomF_tuned_smote': rf_tuned_smote  # Replace with your actual model object\n",
        "}\n",
        "\n",
        "# Pickle each model in the dictionary\n",
        "for model_name, model in models_dict.items():\n",
        "    with open(f'{model_name}.pkl', 'wb') as file:\n",
        "        pickle.dump(model, file)\n",
        "        print(f\"Pickled model: {model_name}\")\n",
        "\n",
        "print(\"All models have been pickled successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6dvkMEZwctK"
      },
      "source": [
        "**Observation:**\n",
        "\n",
        "Exploratory Data Analysis:\n",
        "\n",
        "* In the customer location feature we can find that irrespective of the location, the percentage ratio of emails being ignored, read and acknowledged are kind of similar. It does not exclusively influence our target variable. It would be better to not consider location as a factor in people ignoring, reading or acknowledging our emails. \n",
        "\n",
        "* In the Email Campaign Type feature, it seems like in campaign type 1 very few emails were sent but has a very high likelihood of getting read. Most emails were sent under email campaign type 2 and most ignored. Seems like campaign 3 was a success as even when less number of emails were sent under campaign 3, more emails were read and acknowledged.\n",
        "\n",
        "* Time email sent category cannot be considered as a relevant factor in classifying the emails. Both the feature importance showed this particular thing. If we consider Time email sent category 2 as middle of the of course they are going to be read and acknowledged more than morning and night.\n",
        "\n",
        "* Analyzing total past communications, we can see that the more the number of previous emails, the more it leads to read and acknowledged emails. This is just about making connection with your customers.\n",
        "\n",
        "* The more the words in an email, the more it has a tendency it has to get ignored. Too lengthy emails are getting ignored.\n",
        "\n",
        "* More images were there in ignored emails.\n",
        "* There are outliers in almost every continuous variable except Word Count and upon analyzing, it was found that outliers make up for more than 5% of the minority data and will influence the results either way, so it was better not to get rid of them.\n",
        "\n",
        "Modeling:\n",
        "* Imbalanced Class Handling techniques such as Undersampling and SMOTE were done after train-test split only on the training data, to make sure that the model doesn't catch up to the test set at all and it remains unknown which somewhat reduced our results.\n",
        "* It is observed that SMOTE worked considerably better than Random Undersampling, it may have led to loss of information.\n",
        "* Decision Tree Model is overfitting. It is working really great on train data and worse on test data.\n",
        "* Hyperparameter tuning isn't improving the results to a great degree.\n",
        "* XGBoost Algorithm worked in the best way possible with such imbalanced data with outliers, followed by Random Forest Hyperparameter Tuned model after feature selection with F1 Score of 0.71 on the test set.\n",
        "\n",
        "\n",
        "Recommendations:\n",
        "\n",
        "Upon this in-depth exploratory data analysis and feature importance of various good models, we came to a conclusion and mentioned some factors that are leading to a higher number of ignored emails and accordingly here are some recommendations. \n",
        "* Email Campaign Type 1 and 3 are doing better than 2. So, focusing on improving 2, can do the trick.\n",
        "* The word count should be reasonable. The content should be crisp and to the point with a few marketing gimmicks.\n",
        "* The number of images and links should be kept in check.\n",
        "* Total past communications had a positive influence, hence having a healthy relationship with customers is a big yes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### End Of The Project ####"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOdO+zQIKFAdMSmIXbjocMI",
      "include_colab_link": true,
      "mount_file_id": "1tRVTGFyi8H7TK4I7TLgrBbapO6r_vQeg",
      "name": "Email Campaign Effectiveness Prediction - Vithika Karan.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
